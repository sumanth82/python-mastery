# Download webpage (js, html, css), grab the data from web page and removing/parse the data that we don't need/need;

# TO SEE WHAT DATA IS ALLOWED TO BE SCRAPED IN ANY WEBSITE, GO TO THE WEBSITE WITH A /robot.txt

# https: // www.airbnb.com/robots.txt

# In order to access a website endpoint using an API, you need a JSON based token to authenticate

https: // www.udemy.com/api-2.0/courses/

# If there is no robots.txt for a website, it means the website says to google rank my website, scrape all the data - I don't care
